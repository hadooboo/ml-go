{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf2e69f-bcd5-4812-a7e0-9c6f4e6207fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "\t\"encoding/csv\"\n",
    "\t\"errors\"\n",
    "\t\"fmt\"\n",
    "\t\"log\"\n",
    "\t\"math\"\n",
    "\t\"math/rand\"\n",
    "\t\"os\"\n",
    "\t\"strconv\"\n",
    "\t\"time\"\n",
    "\n",
    "\n",
    "\t\"gonum.org/v1/gonum/floats\"\n",
    "\t\"gonum.org/v1/gonum/mat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78612bba-35f2-4443-9cdb-eb1b8a715457",
   "metadata": {},
   "outputs": [],
   "source": [
    "// neuralNet contains all of the information\n",
    "// that defines a trained neural network.\n",
    "type neuralNet struct {\n",
    "\tconfig  neuralNetConfig\n",
    "\twHidden *mat.Dense\n",
    "\tbHidden *mat.Dense\n",
    "\twOut    *mat.Dense\n",
    "\tbOut    *mat.Dense\n",
    "}\n",
    "\n",
    "// neuralNetConfig defines our nueral network\n",
    "// architecture and learning parameters.\n",
    "type neuralNetConfig struct {\n",
    "\tinputNeurons  int\n",
    "\toutputNeurons int\n",
    "\thiddenNeurons int\n",
    "\tnumEpochs     int\n",
    "\tlearningRate  float64\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "812b4513-c1a5-4518-82d4-cead0b58c92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "// NewNetwork initializes a new neural network.\n",
    "func newNetwork(config neuralNetConfig) *neuralNet {\n",
    "\treturn &neuralNet{config: config}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a6df97-feb5-4b26-82eb-64274ab27f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "// sigmoid implements the sigmoid function\n",
    "// for use in activation functions.\n",
    "func sigmoid(x float64) float64 {\n",
    "\treturn 1.0 / (1.0 + math.Exp(-x))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ceacc9f0-0338-41c5-b454-56005e5e068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "// sigmoidPrime implements the derivative\n",
    "// of the sigmoid function for backpropagation.\n",
    "func sigmoidPrime(x float64) float64 {\n",
    "\treturn x * (1.0 - x)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72374c7e-fab7-4e38-97b2-f2156286d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "// sumAlongAxis sums a matrix along a\n",
    "// particular dimension, preserving the\n",
    "// other dimension.\n",
    "func sumAlongAxis(axis int, m *mat.Dense) (*mat.Dense, error) {\n",
    "\n",
    "\tnumRows, numCols := m.Dims()\n",
    "\n",
    "\tvar output *mat.Dense\n",
    "\n",
    "\tswitch axis {\n",
    "\tcase 0:\n",
    "\t\tdata := make([]float64, numCols)\n",
    "\t\tfor i := 0; i < numCols; i++ {\n",
    "\t\t\tcol := mat.Col(nil, i, m)\n",
    "\t\t\tdata[i] = floats.Sum(col)\n",
    "\t\t}\n",
    "\t\toutput = mat.NewDense(1, numCols, data)\n",
    "\tcase 1:\n",
    "\t\tdata := make([]float64, numRows)\n",
    "\t\tfor i := 0; i < numRows; i++ {\n",
    "\t\t\trow := mat.Row(nil, i, m)\n",
    "\t\t\tdata[i] = floats.Sum(row)\n",
    "\t\t}\n",
    "\t\toutput = mat.NewDense(numRows, 1, data)\n",
    "\tdefault:\n",
    "\t\treturn nil, errors.New(\"invalid axis, must be 0 or 1\")\n",
    "\t}\n",
    "\n",
    "\treturn output, nil\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb102b66-4c5c-4c1b-a2e4-ac978c4e9eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Train trains a neural network using backpropagation.\n",
    "func (nn *neuralNet) train(x, y *mat.Dense) error {\n",
    "\n",
    "\t// Initialize biases/weights.\n",
    "\trandSource := rand.NewSource(time.Now().UnixNano())\n",
    "\trandGen := rand.New(randSource)\n",
    "\n",
    "\twHiddenRaw := make([]float64, nn.config.hiddenNeurons*nn.config.inputNeurons)\n",
    "\tbHiddenRaw := make([]float64, nn.config.hiddenNeurons)\n",
    "\twOutRaw := make([]float64, nn.config.outputNeurons*nn.config.hiddenNeurons)\n",
    "\tbOutRaw := make([]float64, nn.config.outputNeurons)\n",
    "\n",
    "\tfor _, param := range [][]float64{wHiddenRaw, bHiddenRaw, wOutRaw, bOutRaw} {\n",
    "\t\tfor i := range param {\n",
    "\t\t\tparam[i] = randGen.Float64()\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\twHidden := mat.NewDense(nn.config.inputNeurons, nn.config.hiddenNeurons, wHiddenRaw)\n",
    "\tbHidden := mat.NewDense(1, nn.config.hiddenNeurons, bHiddenRaw)\n",
    "\twOut := mat.NewDense(nn.config.hiddenNeurons, nn.config.outputNeurons, wOutRaw)\n",
    "\tbOut := mat.NewDense(1, nn.config.outputNeurons, bOutRaw)\n",
    "\n",
    "\t// Define the output of the neural network.\n",
    "\toutput := new(mat.Dense)\n",
    "\n",
    "\t// Loop over the number of epochs utilizing\n",
    "\t// backpropagation to train our model.\n",
    "\tfor i := 0; i < nn.config.numEpochs; i++ {\n",
    "\n",
    "\t\t// Complete the feed forward process.\n",
    "\t\thiddenLayerInput := new(mat.Dense)\n",
    "\t\thiddenLayerInput.Mul(x, wHidden)\n",
    "\t\taddBHidden := func(_, col int, v float64) float64 { return v + bHidden.At(0, col) }\n",
    "\t\thiddenLayerInput.Apply(addBHidden, hiddenLayerInput)\n",
    "\n",
    "\t\thiddenLayerActivations := new(mat.Dense)\n",
    "\t\tapplySigmoid := func(_, _ int, v float64) float64 { return sigmoid(v) }\n",
    "\t\thiddenLayerActivations.Apply(applySigmoid, hiddenLayerInput)\n",
    "\n",
    "\t\toutputLayerInput := new(mat.Dense)\n",
    "\t\toutputLayerInput.Mul(hiddenLayerActivations, wOut)\n",
    "\t\taddBOut := func(_, col int, v float64) float64 { return v + bOut.At(0, col) }\n",
    "\t\toutputLayerInput.Apply(addBOut, outputLayerInput)\n",
    "\t\toutput.Apply(applySigmoid, outputLayerInput)\n",
    "\n",
    "\t\t// Complete the backpropagation.\n",
    "\t\tnetworkError := new(mat.Dense)\n",
    "\t\tnetworkError.Sub(y, output)\n",
    "\n",
    "\t\tslopeOutputLayer := new(mat.Dense)\n",
    "\t\tapplySigmoidPrime := func(_, _ int, v float64) float64 { return sigmoidPrime(v) }\n",
    "\t\tslopeOutputLayer.Apply(applySigmoidPrime, output)\n",
    "\t\tslopeHiddenLayer := new(mat.Dense)\n",
    "\t\tslopeHiddenLayer.Apply(applySigmoidPrime, hiddenLayerActivations)\n",
    "\n",
    "\t\tdOutput := new(mat.Dense)\n",
    "\t\tdOutput.MulElem(networkError, slopeOutputLayer)\n",
    "\t\terrorAtHiddenLayer := new(mat.Dense)\n",
    "\t\terrorAtHiddenLayer.Mul(dOutput, wOut.T())\n",
    "\n",
    "\t\tdHiddenLayer := new(mat.Dense)\n",
    "\t\tdHiddenLayer.MulElem(errorAtHiddenLayer, slopeHiddenLayer)\n",
    "\n",
    "\t\t// Adjust the parameters.\n",
    "\t\twOutAdj := new(mat.Dense)\n",
    "\t\twOutAdj.Mul(hiddenLayerActivations.T(), dOutput)\n",
    "\t\twOutAdj.Scale(nn.config.learningRate, wOutAdj)\n",
    "\t\twOut.Add(wOut, wOutAdj)\n",
    "\n",
    "\t\tbOutAdj, err := sumAlongAxis(0, dOutput)\n",
    "\t\tif err != nil {\n",
    "\t\t\treturn err\n",
    "\t\t}\n",
    "\t\tbOutAdj.Scale(nn.config.learningRate, bOutAdj)\n",
    "\t\tbOut.Add(bOut, bOutAdj)\n",
    "\n",
    "\t\twHiddenAdj := new(mat.Dense)\n",
    "\t\twHiddenAdj.Mul(x.T(), dHiddenLayer)\n",
    "\t\twHiddenAdj.Scale(nn.config.learningRate, wHiddenAdj)\n",
    "\t\twHidden.Add(wHidden, wHiddenAdj)\n",
    "\n",
    "\t\tbHiddenAdj, err := sumAlongAxis(0, dHiddenLayer)\n",
    "\t\tif err != nil {\n",
    "\t\t\treturn err\n",
    "\t\t}\n",
    "\t\tbHiddenAdj.Scale(nn.config.learningRate, bHiddenAdj)\n",
    "\t\tbHidden.Add(bHidden, bHiddenAdj)\n",
    "\t}\n",
    "\n",
    "\t// Define our trained neural network.\n",
    "\tnn.wHidden = wHidden\n",
    "\tnn.bHidden = bHidden\n",
    "\tnn.wOut = wOut\n",
    "\tnn.bOut = bOut\n",
    "\n",
    "\treturn nil\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "752593b6-6d63-4405-991b-afb19cf917d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "// predict makes a prediction based on a trained\n",
    "// neural network.\n",
    "func (nn *neuralNet) predict(x *mat.Dense) (*mat.Dense, error) {\n",
    "\n",
    "\t// Check to make sure that our neuralNet value\n",
    "\t// represents a trained model.\n",
    "\tif nn.wHidden == nil || nn.wOut == nil || nn.bHidden == nil || nn.bOut == nil {\n",
    "\t\treturn nil, errors.New(\"the supplied neurnal net weights and biases are empty\")\n",
    "\t}\n",
    "\n",
    "\t// Define the output of the neural network.\n",
    "\toutput := new(mat.Dense)\n",
    "\n",
    "\t// Complete the feed forward process.\n",
    "\thiddenLayerInput := new(mat.Dense)\n",
    "\thiddenLayerInput.Mul(x, nn.wHidden)\n",
    "\taddBHidden := func(_, col int, v float64) float64 { return v + nn.bHidden.At(0, col) }\n",
    "\thiddenLayerInput.Apply(addBHidden, hiddenLayerInput)\n",
    "\n",
    "\thiddenLayerActivations := new(mat.Dense)\n",
    "\tapplySigmoid := func(_, _ int, v float64) float64 { return sigmoid(v) }\n",
    "\thiddenLayerActivations.Apply(applySigmoid, hiddenLayerInput)\n",
    "\n",
    "\toutputLayerInput := new(mat.Dense)\n",
    "\toutputLayerInput.Mul(hiddenLayerActivations, nn.wOut)\n",
    "\taddBOut := func(_, col int, v float64) float64 { return v + nn.bOut.At(0, col) }\n",
    "\toutputLayerInput.Apply(addBOut, outputLayerInput)\n",
    "\toutput.Apply(applySigmoid, outputLayerInput)\n",
    "\n",
    "\treturn output, nil\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d84e8d5-6eed-4907-b779-bccd45cd94d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy = 0.97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "func main() {\n",
    "\n",
    "\t// Open the training dataset file.\n",
    "\tf, err := os.Open(\"train.csv\")\n",
    "\tif err != nil {\n",
    "\t\tlog.Fatal(err)\n",
    "\t}\n",
    "\tdefer f.Close()\n",
    "\n",
    "\t// Create a new CSV reader reading from the opened file.\n",
    "\treader := csv.NewReader(f)\n",
    "\treader.FieldsPerRecord = 7\n",
    "\n",
    "\t// Read in all of the CSV records\n",
    "\trawCSVData, err := reader.ReadAll()\n",
    "\tif err != nil {\n",
    "\t\tlog.Fatal(err)\n",
    "\t}\n",
    "\n",
    "\t// inputsData and labelsData will hold all the\n",
    "\t// float values that will eventually be\n",
    "\t// used to form our matrices.\n",
    "\tinputsData := make([]float64, 4*len(rawCSVData))\n",
    "\tlabelsData := make([]float64, 3*len(rawCSVData))\n",
    "\n",
    "\t// inputsIndex will track the current index of\n",
    "\t// inputs matrix values.\n",
    "\tvar inputsIndex int\n",
    "\tvar labelsIndex int\n",
    "\n",
    "\t// Sequentially move the rows into a slice of floats.\n",
    "\tfor idx, record := range rawCSVData {\n",
    "\n",
    "\t\t// Skip the header row.\n",
    "\t\tif idx == 0 {\n",
    "\t\t\tcontinue\n",
    "\t\t}\n",
    "\n",
    "\t\t// Loop over the float columns.\n",
    "\t\tfor i, val := range record {\n",
    "\n",
    "\t\t\t// Convert the value to a float.\n",
    "\t\t\tparsedVal, err := strconv.ParseFloat(val, 64)\n",
    "\t\t\tif err != nil {\n",
    "\t\t\t\tlog.Fatal(err)\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\t// Add to the labelsData if relevant.\n",
    "\t\t\tif i == 4 || i == 5 || i == 6 {\n",
    "\t\t\t\tlabelsData[labelsIndex] = parsedVal\n",
    "\t\t\t\tlabelsIndex++\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\t// Add the float value to the slice of floats.\n",
    "\t\t\tinputsData[inputsIndex] = parsedVal\n",
    "\t\t\tinputsIndex++\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\t// Form the matrices.\n",
    "\tinputs := mat.NewDense(len(rawCSVData), 4, inputsData)\n",
    "\tlabels := mat.NewDense(len(rawCSVData), 3, labelsData)\n",
    "\n",
    "\t// Define our network architecture and\n",
    "\t// learning parameters.\n",
    "\tconfig := neuralNetConfig{\n",
    "\t\tinputNeurons:  4,\n",
    "\t\toutputNeurons: 3,\n",
    "\t\thiddenNeurons: 3,\n",
    "\t\tnumEpochs:     5000,\n",
    "\t\tlearningRate:  0.3,\n",
    "\t}\n",
    "\n",
    "\t// Train the neural network.\n",
    "\tnetwork := newNetwork(config)\n",
    "\tif err := network.train(inputs, labels); err != nil {\n",
    "\t\tlog.Fatal(err)\n",
    "\t}\n",
    "\n",
    "\t// Open the test dataset file.\n",
    "\tf, err = os.Open(\"test.csv\")\n",
    "\tif err != nil {\n",
    "\t\tlog.Fatal(err)\n",
    "\t}\n",
    "\tdefer f.Close()\n",
    "\n",
    "\t// Create a new CSV reader reading from the opened file.\n",
    "\treader = csv.NewReader(f)\n",
    "\treader.FieldsPerRecord = 7\n",
    "\n",
    "\t// Read in all of the test CSV records\n",
    "\trawCSVData, err = reader.ReadAll()\n",
    "\tif err != nil {\n",
    "\t\tlog.Fatal(err)\n",
    "\t}\n",
    "\n",
    "\t// inputsData and labelsData will hold all the\n",
    "\t// float values that will eventually be\n",
    "\t// used to form our matrices.\n",
    "\tinputsData = make([]float64, 4*len(rawCSVData))\n",
    "\tlabelsData = make([]float64, 3*len(rawCSVData))\n",
    "\n",
    "\t// inputsIndex will track the current index of\n",
    "\t// inputs matrix values.\n",
    "\tinputsIndex = 0\n",
    "\tlabelsIndex = 0\n",
    "\n",
    "\t// Sequentially move the rows into a slice of floats.\n",
    "\tfor idx, record := range rawCSVData {\n",
    "\n",
    "\t\t// Skip the header row.\n",
    "\t\tif idx == 0 {\n",
    "\t\t\tcontinue\n",
    "\t\t}\n",
    "\n",
    "\t\t// Loop over the float columns.\n",
    "\t\tfor i, val := range record {\n",
    "\n",
    "\t\t\t// Convert the value to a float.\n",
    "\t\t\tparsedVal, err := strconv.ParseFloat(val, 64)\n",
    "\t\t\tif err != nil {\n",
    "\t\t\t\tlog.Fatal(err)\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\t// Add to the labelsData if relevant.\n",
    "\t\t\tif i == 4 || i == 5 || i == 6 {\n",
    "\t\t\t\tlabelsData[labelsIndex] = parsedVal\n",
    "\t\t\t\tlabelsIndex++\n",
    "\t\t\t\tcontinue\n",
    "\t\t\t}\n",
    "\n",
    "\t\t\t// Add the float value to the slice of floats.\n",
    "\t\t\tinputsData[inputsIndex] = parsedVal\n",
    "\t\t\tinputsIndex++\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\t// Form the matrices.\n",
    "\ttestInputs := mat.NewDense(len(rawCSVData), 4, inputsData)\n",
    "\ttestLabels := mat.NewDense(len(rawCSVData), 3, labelsData)\n",
    "\n",
    "\t// Make the predictions using the trained model.\n",
    "\tpredictions, err := network.predict(testInputs)\n",
    "\tif err != nil {\n",
    "\t\tlog.Fatal(err)\n",
    "\t}\n",
    "\n",
    "\t// Calculate the accuracy of our model.\n",
    "\tvar truePosNeg int\n",
    "\tnumPreds, _ := predictions.Dims()\n",
    "\tfor i := 0; i < numPreds; i++ {\n",
    "\n",
    "\t\t// Get the label.\n",
    "\t\tlabelRow := mat.Row(nil, i, testLabels)\n",
    "\t\tvar species int\n",
    "\t\tfor idx, label := range labelRow {\n",
    "\t\t\tif label == 1.0 {\n",
    "\t\t\t\tspecies = idx\n",
    "\t\t\t\tbreak\n",
    "\t\t\t}\n",
    "\t\t}\n",
    "\n",
    "\t\t// Accumulate the true positive/negative count.\n",
    "\t\tif predictions.At(i, species) == floats.Max(mat.Row(nil, i, predictions)) {\n",
    "\t\t\ttruePosNeg++\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\t// Calculate the accuracy (subset accuracy).\n",
    "\taccuracy := float64(truePosNeg) / float64(numPreds)\n",
    "\n",
    "\t// Output the Accuracy value to standard out.\n",
    "\tfmt.Printf(\"\\nAccuracy = %0.2f\\n\\n\", accuracy)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848f41d2-4f5d-48ea-814b-2fa73e9bd052",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go (gonb)",
   "language": "go",
   "name": "gonb"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.20.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
